module.exports =
/******/ (function(modules) { // webpackBootstrap
/******/ 	// The module cache
/******/ 	var installedModules = {};
/******/
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/
/******/ 		// Check if module is in cache
/******/ 		if(installedModules[moduleId]) {
/******/ 			return installedModules[moduleId].exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = installedModules[moduleId] = {
/******/ 			i: moduleId,
/******/ 			l: false,
/******/ 			exports: {}
/******/ 		};
/******/
/******/ 		// Execute the module function
/******/ 		modules[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/
/******/ 		// Flag the module as loaded
/******/ 		module.l = true;
/******/
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/
/******/
/******/ 	// expose the modules object (__webpack_modules__)
/******/ 	__webpack_require__.m = modules;
/******/
/******/ 	// expose the module cache
/******/ 	__webpack_require__.c = installedModules;
/******/
/******/ 	// define getter function for harmony exports
/******/ 	__webpack_require__.d = function(exports, name, getter) {
/******/ 		if(!__webpack_require__.o(exports, name)) {
/******/ 			Object.defineProperty(exports, name, { enumerable: true, get: getter });
/******/ 		}
/******/ 	};
/******/
/******/ 	// define __esModule on exports
/******/ 	__webpack_require__.r = function(exports) {
/******/ 		if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 			Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 		}
/******/ 		Object.defineProperty(exports, '__esModule', { value: true });
/******/ 	};
/******/
/******/ 	// create a fake namespace object
/******/ 	// mode & 1: value is a module id, require it
/******/ 	// mode & 2: merge all properties of value into the ns
/******/ 	// mode & 4: return value when already ns object
/******/ 	// mode & 8|1: behave like require
/******/ 	__webpack_require__.t = function(value, mode) {
/******/ 		if(mode & 1) value = __webpack_require__(value);
/******/ 		if(mode & 8) return value;
/******/ 		if((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;
/******/ 		var ns = Object.create(null);
/******/ 		__webpack_require__.r(ns);
/******/ 		Object.defineProperty(ns, 'default', { enumerable: true, value: value });
/******/ 		if(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));
/******/ 		return ns;
/******/ 	};
/******/
/******/ 	// getDefaultExport function for compatibility with non-harmony modules
/******/ 	__webpack_require__.n = function(module) {
/******/ 		var getter = module && module.__esModule ?
/******/ 			function getDefault() { return module['default']; } :
/******/ 			function getModuleExports() { return module; };
/******/ 		__webpack_require__.d(getter, 'a', getter);
/******/ 		return getter;
/******/ 	};
/******/
/******/ 	// Object.prototype.hasOwnProperty.call
/******/ 	__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };
/******/
/******/ 	// __webpack_public_path__
/******/ 	__webpack_require__.p = "/";
/******/
/******/
/******/ 	// Load entry module and return exports
/******/ 	return __webpack_require__(__webpack_require__.s = 0);
/******/ })
/************************************************************************/
/******/ ({

/***/ "../../node_modules/moo/moo.js":
/*!*******************************************************!*\
  !*** /Users/leif/chroma/fund/node_modules/moo/moo.js ***!
  \*******************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("var __WEBPACK_AMD_DEFINE_FACTORY__, __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;(function(root, factory) {\n  if (true) {\n    !(__WEBPACK_AMD_DEFINE_ARRAY__ = [], __WEBPACK_AMD_DEFINE_FACTORY__ = (factory),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ = (typeof __WEBPACK_AMD_DEFINE_FACTORY__ === 'function' ?\n\t\t\t\t(__WEBPACK_AMD_DEFINE_FACTORY__.apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__)) : __WEBPACK_AMD_DEFINE_FACTORY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__)) /* global define */\n  } else {}\n}(this, function() {\n  'use strict';\n\n  var hasOwnProperty = Object.prototype.hasOwnProperty\n  var toString = Object.prototype.toString\n  var hasSticky = typeof new RegExp().sticky === 'boolean'\n\n  /***************************************************************************/\n\n  function isRegExp(o) { return o && toString.call(o) === '[object RegExp]' }\n  function isObject(o) { return o && typeof o === 'object' && !isRegExp(o) && !Array.isArray(o) }\n\n  function reEscape(s) {\n    return s.replace(/[-\\/\\\\^$*+?.()|[\\]{}]/g, '\\\\$&')\n  }\n  function reGroups(s) {\n    var re = new RegExp('|' + s)\n    return re.exec('').length - 1\n  }\n  function reCapture(s) {\n    return '(' + s + ')'\n  }\n  function reUnion(regexps) {\n    if (!regexps.length) return '(?!)'\n    var source =  regexps.map(function(s) {\n      return \"(?:\" + s + \")\"\n    }).join('|')\n    return \"(?:\" + source + \")\"\n  }\n\n  function regexpOrLiteral(obj) {\n    if (typeof obj === 'string') {\n      return '(?:' + reEscape(obj) + ')'\n\n    } else if (isRegExp(obj)) {\n      // TODO: consider /u support\n      if (obj.ignoreCase) throw new Error('RegExp /i flag not allowed')\n      if (obj.global) throw new Error('RegExp /g flag is implied')\n      if (obj.sticky) throw new Error('RegExp /y flag is implied')\n      if (obj.multiline) throw new Error('RegExp /m flag is implied')\n      if (obj.unicode) throw new Error('RegExp /u flag is not allowed')\n      return obj.source\n\n    } else {\n      throw new Error('Not a pattern: ' + obj)\n    }\n  }\n\n  function objectToRules(object) {\n    var keys = Object.getOwnPropertyNames(object)\n    var result = []\n    for (var i = 0; i < keys.length; i++) {\n      var key = keys[i]\n      var thing = object[key]\n      var rules = [].concat(thing)\n      if (key === 'include') {\n        for (var j = 0; j < rules.length; j++) {\n          result.push({include: rules[j]})\n        }\n        continue\n      }\n      var match = []\n      rules.forEach(function(rule) {\n        if (isObject(rule)) {\n          if (match.length) result.push(ruleOptions(key, match))\n          result.push(ruleOptions(key, rule))\n          match = []\n        } else {\n          match.push(rule)\n        }\n      })\n      if (match.length) result.push(ruleOptions(key, match))\n    }\n    return result\n  }\n\n  function arrayToRules(array) {\n    var result = []\n    for (var i = 0; i < array.length; i++) {\n      var obj = array[i]\n      if (obj.include) {\n        var include = [].concat(obj.include)\n        for (var j = 0; j < include.length; j++) {\n          result.push({include: include[j]})\n        }\n        continue\n      }\n      if (!obj.type) {\n        throw new Error('Rule has no type: ' + JSON.stringify(obj))\n      }\n      result.push(ruleOptions(obj.type, obj))\n    }\n    return result\n  }\n\n  function ruleOptions(type, obj) {\n    if (!isObject(obj)) {\n      obj = { match: obj }\n    }\n    if (obj.include) {\n      throw new Error('Matching rules cannot also include states')\n    }\n\n    // nb. error and fallback imply lineBreaks\n    var options = {\n      defaultType: type,\n      lineBreaks: !!obj.error || !!obj.fallback,\n      pop: false,\n      next: null,\n      push: null,\n      error: false,\n      fallback: false,\n      value: null,\n      type: null,\n      shouldThrow: false,\n    }\n\n    // Avoid Object.assign(), so we support IE9+\n    for (var key in obj) {\n      if (hasOwnProperty.call(obj, key)) {\n        options[key] = obj[key]\n      }\n    }\n\n    // type transform cannot be a string\n    if (typeof options.type === 'string' && type !== options.type) {\n      throw new Error(\"Type transform cannot be a string (type '\" + options.type + \"' for token '\" + type + \"')\")\n    }\n\n    // convert to array\n    var match = options.match\n    options.match = Array.isArray(match) ? match : match ? [match] : []\n    options.match.sort(function(a, b) {\n      return isRegExp(a) && isRegExp(b) ? 0\n           : isRegExp(b) ? -1 : isRegExp(a) ? +1 : b.length - a.length\n    })\n    return options\n  }\n\n  function toRules(spec) {\n    return Array.isArray(spec) ? arrayToRules(spec) : objectToRules(spec)\n  }\n\n  var defaultErrorRule = ruleOptions('error', {lineBreaks: true, shouldThrow: true})\n  function compileRules(rules, hasStates) {\n    var errorRule = null\n    var fast = Object.create(null)\n    var fastAllowed = true\n    var groups = []\n    var parts = []\n\n    // If there is a fallback rule, then disable fast matching\n    for (var i = 0; i < rules.length; i++) {\n      if (rules[i].fallback) {\n        fastAllowed = false\n      }\n    }\n\n    for (var i = 0; i < rules.length; i++) {\n      var options = rules[i]\n\n      if (options.include) {\n        // all valid inclusions are removed by states() preprocessor\n        throw new Error('Inheritance is not allowed in stateless lexers')\n      }\n\n      if (options.error || options.fallback) {\n        // errorRule can only be set once\n        if (errorRule) {\n          if (!options.fallback === !errorRule.fallback) {\n            throw new Error(\"Multiple \" + (options.fallback ? \"fallback\" : \"error\") + \" rules not allowed (for token '\" + options.defaultType + \"')\")\n          } else {\n            throw new Error(\"fallback and error are mutually exclusive (for token '\" + options.defaultType + \"')\")\n          }\n        }\n        errorRule = options\n      }\n\n      var match = options.match\n      if (fastAllowed) {\n        while (match.length && typeof match[0] === 'string' && match[0].length === 1) {\n          var word = match.shift()\n          fast[word.charCodeAt(0)] = options\n        }\n      }\n\n      // Warn about inappropriate state-switching options\n      if (options.pop || options.push || options.next) {\n        if (!hasStates) {\n          throw new Error(\"State-switching options are not allowed in stateless lexers (for token '\" + options.defaultType + \"')\")\n        }\n        if (options.fallback) {\n          throw new Error(\"State-switching options are not allowed on fallback tokens (for token '\" + options.defaultType + \"')\")\n        }\n      }\n\n      // Only rules with a .match are included in the RegExp\n      if (match.length === 0) {\n        continue\n      }\n      fastAllowed = false\n\n      groups.push(options)\n\n      // convert to RegExp\n      var pat = reUnion(match.map(regexpOrLiteral))\n\n      // validate\n      var regexp = new RegExp(pat)\n      if (regexp.test(\"\")) {\n        throw new Error(\"RegExp matches empty string: \" + regexp)\n      }\n      var groupCount = reGroups(pat)\n      if (groupCount > 0) {\n        throw new Error(\"RegExp has capture groups: \" + regexp + \"\\nUse (?: … ) instead\")\n      }\n\n      // try and detect rules matching newlines\n      if (!options.lineBreaks && regexp.test('\\n')) {\n        throw new Error('Rule should declare lineBreaks: ' + regexp)\n      }\n\n      // store regex\n      parts.push(reCapture(pat))\n    }\n\n\n    // If there's no fallback rule, use the sticky flag so we only look for\n    // matches at the current index.\n    //\n    // If we don't support the sticky flag, then fake it using an irrefutable\n    // match (i.e. an empty pattern).\n    var fallbackRule = errorRule && errorRule.fallback\n    var flags = hasSticky && !fallbackRule ? 'ym' : 'gm'\n    var suffix = hasSticky || fallbackRule ? '' : '|'\n    var combined = new RegExp(reUnion(parts) + suffix, flags)\n\n    return {regexp: combined, groups: groups, fast: fast, error: errorRule || defaultErrorRule}\n  }\n\n  function compile(rules) {\n    var result = compileRules(toRules(rules))\n    return new Lexer({start: result}, 'start')\n  }\n\n  function checkStateGroup(g, name, map) {\n    var state = g && (g.push || g.next)\n    if (state && !map[state]) {\n      throw new Error(\"Missing state '\" + state + \"' (in token '\" + g.defaultType + \"' of state '\" + name + \"')\")\n    }\n    if (g && g.pop && +g.pop !== 1) {\n      throw new Error(\"pop must be 1 (in token '\" + g.defaultType + \"' of state '\" + name + \"')\")\n    }\n  }\n  function compileStates(states, start) {\n    var all = states.$all ? toRules(states.$all) : []\n    delete states.$all\n\n    var keys = Object.getOwnPropertyNames(states)\n    if (!start) start = keys[0]\n\n    var ruleMap = Object.create(null)\n    for (var i = 0; i < keys.length; i++) {\n      var key = keys[i]\n      ruleMap[key] = toRules(states[key]).concat(all)\n    }\n    for (var i = 0; i < keys.length; i++) {\n      var key = keys[i]\n      var rules = ruleMap[key]\n      var included = Object.create(null)\n      for (var j = 0; j < rules.length; j++) {\n        var rule = rules[j]\n        if (!rule.include) continue\n        var splice = [j, 1]\n        if (rule.include !== key && !included[rule.include]) {\n          included[rule.include] = true\n          var newRules = ruleMap[rule.include]\n          if (!newRules) {\n            throw new Error(\"Cannot include nonexistent state '\" + rule.include + \"' (in state '\" + key + \"')\")\n          }\n          for (var k = 0; k < newRules.length; k++) {\n            var newRule = newRules[k]\n            if (rules.indexOf(newRule) !== -1) continue\n            splice.push(newRule)\n          }\n        }\n        rules.splice.apply(rules, splice)\n        j--\n      }\n    }\n\n    var map = Object.create(null)\n    for (var i = 0; i < keys.length; i++) {\n      var key = keys[i]\n      map[key] = compileRules(ruleMap[key], true)\n    }\n\n    for (var i = 0; i < keys.length; i++) {\n      var name = keys[i]\n      var state = map[name]\n      var groups = state.groups\n      for (var j = 0; j < groups.length; j++) {\n        checkStateGroup(groups[j], name, map)\n      }\n      var fastKeys = Object.getOwnPropertyNames(state.fast)\n      for (var j = 0; j < fastKeys.length; j++) {\n        checkStateGroup(state.fast[fastKeys[j]], name, map)\n      }\n    }\n\n    return new Lexer(map, start)\n  }\n\n  function keywordTransform(map) {\n    var reverseMap = Object.create(null)\n    var byLength = Object.create(null)\n    var types = Object.getOwnPropertyNames(map)\n    for (var i = 0; i < types.length; i++) {\n      var tokenType = types[i]\n      var item = map[tokenType]\n      var keywordList = Array.isArray(item) ? item : [item]\n      keywordList.forEach(function(keyword) {\n        (byLength[keyword.length] = byLength[keyword.length] || []).push(keyword)\n        if (typeof keyword !== 'string') {\n          throw new Error(\"keyword must be string (in keyword '\" + tokenType + \"')\")\n        }\n        reverseMap[keyword] = tokenType\n      })\n    }\n\n    // fast string lookup\n    // https://jsperf.com/string-lookups\n    function str(x) { return JSON.stringify(x) }\n    var source = ''\n    source += 'switch (value.length) {\\n'\n    for (var length in byLength) {\n      var keywords = byLength[length]\n      source += 'case ' + length + ':\\n'\n      source += 'switch (value) {\\n'\n      keywords.forEach(function(keyword) {\n        var tokenType = reverseMap[keyword]\n        source += 'case ' + str(keyword) + ': return ' + str(tokenType) + '\\n'\n      })\n      source += '}\\n'\n    }\n    source += '}\\n'\n    return Function('value', source) // type\n  }\n\n  /***************************************************************************/\n\n  var Lexer = function(states, state) {\n    this.startState = state\n    this.states = states\n    this.buffer = ''\n    this.stack = []\n    this.reset()\n  }\n\n  Lexer.prototype.reset = function(data, info) {\n    this.buffer = data || ''\n    this.index = 0\n    this.line = info ? info.line : 1\n    this.col = info ? info.col : 1\n    this.queuedToken = info ? info.queuedToken : null\n    this.queuedThrow = info ? info.queuedThrow : null\n    this.setState(info ? info.state : this.startState)\n    this.stack = info && info.stack ? info.stack.slice() : []\n    return this\n  }\n\n  Lexer.prototype.save = function() {\n    return {\n      line: this.line,\n      col: this.col,\n      state: this.state,\n      stack: this.stack.slice(),\n      queuedToken: this.queuedToken,\n      queuedThrow: this.queuedThrow,\n    }\n  }\n\n  Lexer.prototype.setState = function(state) {\n    if (!state || this.state === state) return\n    this.state = state\n    var info = this.states[state]\n    this.groups = info.groups\n    this.error = info.error\n    this.re = info.regexp\n    this.fast = info.fast\n  }\n\n  Lexer.prototype.popState = function() {\n    this.setState(this.stack.pop())\n  }\n\n  Lexer.prototype.pushState = function(state) {\n    this.stack.push(this.state)\n    this.setState(state)\n  }\n\n  var eat = hasSticky ? function(re, buffer) { // assume re is /y\n    return re.exec(buffer)\n  } : function(re, buffer) { // assume re is /g\n    var match = re.exec(buffer)\n    // will always match, since we used the |(?:) trick\n    if (match[0].length === 0) {\n      return null\n    }\n    return match\n  }\n\n  Lexer.prototype._getGroup = function(match) {\n    var groupCount = this.groups.length\n    for (var i = 0; i < groupCount; i++) {\n      if (match[i + 1] !== undefined) {\n        return this.groups[i]\n      }\n    }\n    throw new Error('Cannot find token type for matched text')\n  }\n\n  function tokenToString() {\n    return this.value\n  }\n\n  Lexer.prototype.next = function() {\n    var index = this.index\n\n    // If a fallback token matched, we don't need to re-run the RegExp\n    if (this.queuedGroup) {\n      var token = this._token(this.queuedGroup, this.queuedText, index)\n      this.queuedGroup = null\n      this.queuedText = \"\"\n      return token\n    }\n\n    var buffer = this.buffer\n    if (index === buffer.length) {\n      return // EOF\n    }\n\n    // Fast matching for single characters\n    var group = this.fast[buffer.charCodeAt(index)]\n    if (group) {\n      return this._token(group, buffer.charAt(index), index)\n    }\n\n    // Execute RegExp\n    var re = this.re\n    re.lastIndex = index\n    var match = eat(re, buffer)\n\n    // Error tokens match the remaining buffer\n    var error = this.error\n    if (match == null) {\n      return this._token(error, buffer.slice(index, buffer.length), index)\n    }\n\n    var group = this._getGroup(match)\n    var text = match[0]\n\n    if (error.fallback && match.index !== index) {\n      this.queuedGroup = group\n      this.queuedText = text\n\n      // Fallback tokens contain the unmatched portion of the buffer\n      return this._token(error, buffer.slice(index, match.index), index)\n    }\n\n    return this._token(group, text, index)\n  }\n\n  Lexer.prototype._token = function(group, text, offset) {\n    // count line breaks\n    var lineBreaks = 0\n    if (group.lineBreaks) {\n      var matchNL = /\\n/g\n      var nl = 1\n      if (text === '\\n') {\n        lineBreaks = 1\n      } else {\n        while (matchNL.exec(text)) { lineBreaks++; nl = matchNL.lastIndex }\n      }\n    }\n\n    var token = {\n      type: (typeof group.type === 'function' && group.type(text)) || group.defaultType,\n      value: typeof group.value === 'function' ? group.value(text) : text,\n      text: text,\n      toString: tokenToString,\n      offset: offset,\n      lineBreaks: lineBreaks,\n      line: this.line,\n      col: this.col,\n    }\n    // nb. adding more props to token object will make V8 sad!\n\n    var size = text.length\n    this.index += size\n    this.line += lineBreaks\n    if (lineBreaks !== 0) {\n      this.col = size - nl + 1\n    } else {\n      this.col += size\n    }\n\n    // throw, if no rule with {error: true}\n    if (group.shouldThrow) {\n      throw new Error(this.formatError(token, \"invalid syntax\"))\n    }\n\n    if (group.pop) this.popState()\n    else if (group.push) this.pushState(group.push)\n    else if (group.next) this.setState(group.next)\n\n    return token\n  }\n\n  if (typeof Symbol !== 'undefined' && Symbol.iterator) {\n    var LexerIterator = function(lexer) {\n      this.lexer = lexer\n    }\n\n    LexerIterator.prototype.next = function() {\n      var token = this.lexer.next()\n      return {value: token, done: !token}\n    }\n\n    LexerIterator.prototype[Symbol.iterator] = function() {\n      return this\n    }\n\n    Lexer.prototype[Symbol.iterator] = function() {\n      return new LexerIterator(this)\n    }\n  }\n\n  Lexer.prototype.formatError = function(token, message) {\n    var value = token.text\n    var index = token.offset\n    var eol = token.lineBreaks ? value.indexOf('\\n') : value.length\n    var start = Math.max(0, index - token.col + 1)\n    var firstLine = this.buffer.substring(start, index + eol)\n    message += \" at line \" + token.line + \" col \" + token.col + \":\\n\\n\"\n    message += \"  \" + firstLine + \"\\n\"\n    message += \"  \" + Array(token.col).join(\" \") + \"^\"\n    return message\n  }\n\n  Lexer.prototype.clone = function() {\n    return new Lexer(this.states, this.state)\n  }\n\n  Lexer.prototype.has = function(tokenType) {\n    return true\n  }\n\n\n  return {\n    compile: compile,\n    states: compileStates,\n    error: Object.freeze({error: true}),\n    fallback: Object.freeze({fallback: true}),\n    keywords: keywordTransform,\n  }\n\n}));\n\n\n//# sourceURL=webpack:////Users/leif/chroma/fund/node_modules/moo/moo.js?");

/***/ }),

/***/ "../../node_modules/nearley/lib/nearley.js":
/*!*******************************************************************!*\
  !*** /Users/leif/chroma/fund/node_modules/nearley/lib/nearley.js ***!
  \*******************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("(function(root, factory) {\n    if ( true && module.exports) {\n        module.exports = factory();\n    } else {\n        root.nearley = factory();\n    }\n}(this, function() {\n\n    function Rule(name, symbols, postprocess) {\n        this.id = ++Rule.highestId;\n        this.name = name;\n        this.symbols = symbols;        // a list of literal | regex class | nonterminal\n        this.postprocess = postprocess;\n        return this;\n    }\n    Rule.highestId = 0;\n\n    Rule.prototype.toString = function(withCursorAt) {\n        function stringifySymbolSequence (e) {\n            return e.literal ? JSON.stringify(e.literal) :\n                   e.type ? '%' + e.type : e.toString();\n        }\n        var symbolSequence = (typeof withCursorAt === \"undefined\")\n                             ? this.symbols.map(stringifySymbolSequence).join(' ')\n                             : (   this.symbols.slice(0, withCursorAt).map(stringifySymbolSequence).join(' ')\n                                 + \" ● \"\n                                 + this.symbols.slice(withCursorAt).map(stringifySymbolSequence).join(' ')     );\n        return this.name + \" → \" + symbolSequence;\n    }\n\n\n    // a State is a rule at a position from a given starting point in the input stream (reference)\n    function State(rule, dot, reference, wantedBy) {\n        this.rule = rule;\n        this.dot = dot;\n        this.reference = reference;\n        this.data = [];\n        this.wantedBy = wantedBy;\n        this.isComplete = this.dot === rule.symbols.length;\n    }\n\n    State.prototype.toString = function() {\n        return \"{\" + this.rule.toString(this.dot) + \"}, from: \" + (this.reference || 0);\n    };\n\n    State.prototype.nextState = function(child) {\n        var state = new State(this.rule, this.dot + 1, this.reference, this.wantedBy);\n        state.left = this;\n        state.right = child;\n        if (state.isComplete) {\n            state.data = state.build();\n        }\n        return state;\n    };\n\n    State.prototype.build = function() {\n        var children = [];\n        var node = this;\n        do {\n            children.push(node.right.data);\n            node = node.left;\n        } while (node.left);\n        children.reverse();\n        return children;\n    };\n\n    State.prototype.finish = function() {\n        if (this.rule.postprocess) {\n            this.data = this.rule.postprocess(this.data, this.reference, Parser.fail);\n        }\n    };\n\n\n    function Column(grammar, index) {\n        this.grammar = grammar;\n        this.index = index;\n        this.states = [];\n        this.wants = {}; // states indexed by the non-terminal they expect\n        this.scannable = []; // list of states that expect a token\n        this.completed = {}; // states that are nullable\n    }\n\n\n    Column.prototype.process = function(nextColumn) {\n        var states = this.states;\n        var wants = this.wants;\n        var completed = this.completed;\n\n        for (var w = 0; w < states.length; w++) { // nb. we push() during iteration\n            var state = states[w];\n\n            if (state.isComplete) {\n                state.finish();\n                if (state.data !== Parser.fail) {\n                    // complete\n                    var wantedBy = state.wantedBy;\n                    for (var i = wantedBy.length; i--; ) { // this line is hot\n                        var left = wantedBy[i];\n                        this.complete(left, state);\n                    }\n\n                    // special-case nullables\n                    if (state.reference === this.index) {\n                        // make sure future predictors of this rule get completed.\n                        var exp = state.rule.name;\n                        (this.completed[exp] = this.completed[exp] || []).push(state);\n                    }\n                }\n\n            } else {\n                // queue scannable states\n                var exp = state.rule.symbols[state.dot];\n                if (typeof exp !== 'string') {\n                    this.scannable.push(state);\n                    continue;\n                }\n\n                // predict\n                if (wants[exp]) {\n                    wants[exp].push(state);\n\n                    if (completed.hasOwnProperty(exp)) {\n                        var nulls = completed[exp];\n                        for (var i = 0; i < nulls.length; i++) {\n                            var right = nulls[i];\n                            this.complete(state, right);\n                        }\n                    }\n                } else {\n                    wants[exp] = [state];\n                    this.predict(exp);\n                }\n            }\n        }\n    }\n\n    Column.prototype.predict = function(exp) {\n        var rules = this.grammar.byName[exp] || [];\n\n        for (var i = 0; i < rules.length; i++) {\n            var r = rules[i];\n            var wantedBy = this.wants[exp];\n            var s = new State(r, 0, this.index, wantedBy);\n            this.states.push(s);\n        }\n    }\n\n    Column.prototype.complete = function(left, right) {\n        var copy = left.nextState(right);\n        this.states.push(copy);\n    }\n\n\n    function Grammar(rules, start) {\n        this.rules = rules;\n        this.start = start || this.rules[0].name;\n        var byName = this.byName = {};\n        this.rules.forEach(function(rule) {\n            if (!byName.hasOwnProperty(rule.name)) {\n                byName[rule.name] = [];\n            }\n            byName[rule.name].push(rule);\n        });\n    }\n\n    // So we can allow passing (rules, start) directly to Parser for backwards compatibility\n    Grammar.fromCompiled = function(rules, start) {\n        var lexer = rules.Lexer;\n        if (rules.ParserStart) {\n          start = rules.ParserStart;\n          rules = rules.ParserRules;\n        }\n        var rules = rules.map(function (r) { return (new Rule(r.name, r.symbols, r.postprocess)); });\n        var g = new Grammar(rules, start);\n        g.lexer = lexer; // nb. storing lexer on Grammar is iffy, but unavoidable\n        return g;\n    }\n\n\n    function StreamLexer() {\n      this.reset(\"\");\n    }\n\n    StreamLexer.prototype.reset = function(data, state) {\n        this.buffer = data;\n        this.index = 0;\n        this.line = state ? state.line : 1;\n        this.lastLineBreak = state ? -state.col : 0;\n    }\n\n    StreamLexer.prototype.next = function() {\n        if (this.index < this.buffer.length) {\n            var ch = this.buffer[this.index++];\n            if (ch === '\\n') {\n              this.line += 1;\n              this.lastLineBreak = this.index;\n            }\n            return {value: ch};\n        }\n    }\n\n    StreamLexer.prototype.save = function() {\n      return {\n        line: this.line,\n        col: this.index - this.lastLineBreak,\n      }\n    }\n\n    StreamLexer.prototype.formatError = function(token, message) {\n        // nb. this gets called after consuming the offending token,\n        // so the culprit is index-1\n        var buffer = this.buffer;\n        if (typeof buffer === 'string') {\n            var nextLineBreak = buffer.indexOf('\\n', this.index);\n            if (nextLineBreak === -1) nextLineBreak = buffer.length;\n            var line = buffer.substring(this.lastLineBreak, nextLineBreak)\n            var col = this.index - this.lastLineBreak;\n            message += \" at line \" + this.line + \" col \" + col + \":\\n\\n\";\n            message += \"  \" + line + \"\\n\"\n            message += \"  \" + Array(col).join(\" \") + \"^\"\n            return message;\n        } else {\n            return message + \" at index \" + (this.index - 1);\n        }\n    }\n\n\n    function Parser(rules, start, options) {\n        if (rules instanceof Grammar) {\n            var grammar = rules;\n            var options = start;\n        } else {\n            var grammar = Grammar.fromCompiled(rules, start);\n        }\n        this.grammar = grammar;\n\n        // Read options\n        this.options = {\n            keepHistory: false,\n            lexer: grammar.lexer || new StreamLexer,\n        };\n        for (var key in (options || {})) {\n            this.options[key] = options[key];\n        }\n\n        // Setup lexer\n        this.lexer = this.options.lexer;\n        this.lexerState = undefined;\n\n        // Setup a table\n        var column = new Column(grammar, 0);\n        var table = this.table = [column];\n\n        // I could be expecting anything.\n        column.wants[grammar.start] = [];\n        column.predict(grammar.start);\n        // TODO what if start rule is nullable?\n        column.process();\n        this.current = 0; // token index\n    }\n\n    // create a reserved token for indicating a parse fail\n    Parser.fail = {};\n\n    Parser.prototype.feed = function(chunk) {\n        var lexer = this.lexer;\n        lexer.reset(chunk, this.lexerState);\n\n        var token;\n        while (token = lexer.next()) {\n            // We add new states to table[current+1]\n            var column = this.table[this.current];\n\n            // GC unused states\n            if (!this.options.keepHistory) {\n                delete this.table[this.current - 1];\n            }\n\n            var n = this.current + 1;\n            var nextColumn = new Column(this.grammar, n);\n            this.table.push(nextColumn);\n\n            // Advance all tokens that expect the symbol\n            var literal = token.text !== undefined ? token.text : token.value;\n            var value = lexer.constructor === StreamLexer ? token.value : token;\n            var scannable = column.scannable;\n            for (var w = scannable.length; w--; ) {\n                var state = scannable[w];\n                var expect = state.rule.symbols[state.dot];\n                // Try to consume the token\n                // either regex or literal\n                if (expect.test ? expect.test(value) :\n                    expect.type ? expect.type === token.type\n                                : expect.literal === literal) {\n                    // Add it\n                    var next = state.nextState({data: value, token: token, isToken: true, reference: n - 1});\n                    nextColumn.states.push(next);\n                }\n            }\n\n            // Next, for each of the rules, we either\n            // (a) complete it, and try to see if the reference row expected that\n            //     rule\n            // (b) predict the next nonterminal it expects by adding that\n            //     nonterminal's start state\n            // To prevent duplication, we also keep track of rules we have already\n            // added\n\n            nextColumn.process();\n\n            // If needed, throw an error:\n            if (nextColumn.states.length === 0) {\n                // No states at all! This is not good.\n                var message = this.lexer.formatError(token, \"invalid syntax\") + \"\\n\";\n                message += \"Unexpected \" + (token.type ? token.type + \" token: \" : \"\");\n                message += JSON.stringify(token.value !== undefined ? token.value : token) + \"\\n\";\n                var err = new Error(message);\n                err.offset = this.current;\n                err.token = token;\n                throw err;\n            }\n\n            // maybe save lexer state\n            if (this.options.keepHistory) {\n              column.lexerState = lexer.save()\n            }\n\n            this.current++;\n        }\n        if (column) {\n          this.lexerState = lexer.save()\n        }\n\n        // Incrementally keep track of results\n        this.results = this.finish();\n\n        // Allow chaining, for whatever it's worth\n        return this;\n    };\n\n    Parser.prototype.save = function() {\n        var column = this.table[this.current];\n        column.lexerState = this.lexerState;\n        return column;\n    };\n\n    Parser.prototype.restore = function(column) {\n        var index = column.index;\n        this.current = index;\n        this.table[index] = column;\n        this.table.splice(index + 1);\n        this.lexerState = column.lexerState;\n\n        // Incrementally keep track of results\n        this.results = this.finish();\n    };\n\n    // nb. deprecated: use save/restore instead!\n    Parser.prototype.rewind = function(index) {\n        if (!this.options.keepHistory) {\n            throw new Error('set option `keepHistory` to enable rewinding')\n        }\n        // nb. recall column (table) indicies fall between token indicies.\n        //        col 0   --   token 0   --   col 1\n        this.restore(this.table[index]);\n    };\n\n    Parser.prototype.finish = function() {\n        // Return the possible parsings\n        var considerations = [];\n        var start = this.grammar.start;\n        var column = this.table[this.table.length - 1]\n        column.states.forEach(function (t) {\n            if (t.rule.name === start\n                    && t.dot === t.rule.symbols.length\n                    && t.reference === 0\n                    && t.data !== Parser.fail) {\n                considerations.push(t);\n            }\n        });\n        return considerations.map(function(c) {return c.data; });\n    };\n\n    return {\n        Parser: Parser,\n        Grammar: Grammar,\n        Rule: Rule,\n    };\n\n}));\n\n\n//# sourceURL=webpack:////Users/leif/chroma/fund/node_modules/nearley/lib/nearley.js?");

/***/ }),

/***/ "./src/index.ts":
/*!**********************!*\
  !*** ./src/index.ts ***!
  \**********************/
/*! exports provided: parse, load, MonacoTokensProvider */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"parse\", function() { return parse; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"load\", function() { return load; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"MonacoTokensProvider\", function() { return MonacoTokensProvider; });\n/* harmony import */ var nearley__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! nearley */ \"../../node_modules/nearley/lib/nearley.js\");\n/* harmony import */ var nearley__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(nearley__WEBPACK_IMPORTED_MODULE_0__);\n\n\nconst grammar = __webpack_require__(/*! ./nearley */ \"./src/nearley/index.ts\");\n\nconst parse = text => {\n  const parser = new nearley__WEBPACK_IMPORTED_MODULE_0__[\"Parser\"](nearley__WEBPACK_IMPORTED_MODULE_0__[\"Grammar\"].fromCompiled(grammar));\n  return parser.feed(text);\n};\nconst load = text => {\n  const parsed = parse(text);\n  return parsed.results[0];\n};\n\nclass ParserState {\n  clone() {\n    return this;\n  }\n\n  equals() {\n    return true;\n  }\n\n}\n\nclass MonacoTokensProvider {\n  constructor() {\n    this.parser = void 0;\n  }\n\n  getInitialState(line) {\n    this.parser = new nearley__WEBPACK_IMPORTED_MODULE_0__[\"Parser\"](nearley__WEBPACK_IMPORTED_MODULE_0__[\"Grammar\"].fromCompiled(grammar));\n    return new ParserState();\n  }\n\n  tokenize(line, state) {\n    // console.log(state);\n    // console.log('tokenize', line, state)\n    const {\n      results,\n      lexer\n    } = this.parser.feed(line);\n    console.log(lexer);\n    return {\n      endState: state,\n      tokens: results[0]\n    };\n  }\n\n}\n\n//# sourceURL=webpack:///./src/index.ts?");

/***/ }),

/***/ "./src/nearley/index.ts":
/*!******************************!*\
  !*** ./src/nearley/index.ts ***!
  \******************************/
/*! exports provided: Lexer, ParserRules, ParserStart */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Lexer\", function() { return Lexer; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ParserRules\", function() { return ParserRules; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ParserStart\", function() { return ParserStart; });\n/* harmony import */ var _lexer__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./lexer */ \"./src/nearley/lexer.ts\");\n/* harmony import */ var _post_errors__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./post/errors */ \"./src/nearley/post/errors.ts\");\n/* harmony import */ var _post_reducers__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./post/reducers */ \"./src/nearley/post/reducers.ts\");\n// Generated automatically by nearley, version 2.16.0\n// http://github.com/Hardmath123/nearley\n// Bypasses TS6133. Allow declared but unused functions.\n// @ts-ignore\nfunction id(d) {\n  return d[0];\n}\n\n\n\n\n;\n;\n;\nvar Lexer = _lexer__WEBPACK_IMPORTED_MODULE_0__[\"lexer\"];\nvar ParserRules = [{\n  \"name\": \"uri\",\n  \"symbols\": [\"url\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"uri\",\n  \"symbols\": [\"authority\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"url\",\n  \"symbols\": [\"urlDomainScheme\", \"authority\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"url\",\n  \"symbols\": [\"urlScheme\", \"uriPathComponent\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"url\",\n  \"symbols\": [\"urlScheme\", \"urlPath\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"urlDomainScheme\",\n  \"symbols\": [\"urlScheme\", {\n    \"literal\": \"/\"\n  }, {\n    \"literal\": \"/\"\n  }],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"urlSchemes\",\n  \"symbols\": [\"urlSchemes\", \"urlScheme\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"urlSchemes\",\n  \"symbols\": [\"urlScheme\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"urlScheme\",\n  \"symbols\": [\"domainComponent\", {\n    \"literal\": \":\"\n  }],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"authority\",\n  \"symbols\": [\"urlCredentials\", {\n    \"literal\": \"@\"\n  }, \"_authority\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"authority\",\n  \"symbols\": [\"_authority\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"_authority$ebnf$1\",\n  \"symbols\": [\"uriPathComponent\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"_authority$ebnf$1\",\n  \"symbols\": [],\n  \"postprocess\": () => null\n}, {\n  \"name\": \"_authority$ebnf$2\",\n  \"symbols\": [\"uriQueries\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"_authority$ebnf$2\",\n  \"symbols\": [],\n  \"postprocess\": () => null\n}, {\n  \"name\": \"_authority$ebnf$3\",\n  \"symbols\": [\"uriFragment\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"_authority$ebnf$3\",\n  \"symbols\": [],\n  \"postprocess\": () => null\n}, {\n  \"name\": \"_authority\",\n  \"symbols\": [\"uriDomainComponent\", \"_authority$ebnf$1\", \"_authority$ebnf$2\", \"_authority$ebnf$3\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"uriQueries\",\n  \"symbols\": [\"uriQueries\", \"uriQuery\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"uriQueries\",\n  \"symbols\": [\"uriQuery\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"uriPathComponent\",\n  \"symbols\": [{\n    \"literal\": \"/\"\n  }, \"urlPath\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"uriPathComponent\",\n  \"symbols\": [{\n    \"literal\": \"/\"\n  }],\n  \"postprocess\": ([tok]) => tok.value\n}, {\n  \"name\": \"urlCredentials\",\n  \"symbols\": [\"urlCredentials\", {\n    \"literal\": \":\"\n  }, \"password\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"urlCredentials\",\n  \"symbols\": [\"email\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"urlCredentials\",\n  \"symbols\": [\"subdomain\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"urlPath\",\n  \"symbols\": [\"urlPath\", {\n    \"literal\": \"/\"\n  }, \"urlPathName\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"urlPath\",\n  \"symbols\": [\"urlPath\", {\n    \"literal\": \"/\"\n  }],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"urlPath\",\n  \"symbols\": [\"urlPathName\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"urlPathName\",\n  \"symbols\": [\"urlPathName\", {\n    \"literal\": \".\"\n  }, \"urlPathWord\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"urlPathName\",\n  \"symbols\": [\"urlPathWord\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"urlPathWord\",\n  \"symbols\": [\"urlPathWord\", \"urlPathChar\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"urlPathWord\",\n  \"symbols\": [\"urlPathChar\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"urlPathChar\",\n  \"symbols\": [/[^ ^\\/^.^?^;]/],\n  \"postprocess\": ([tok]) => tok.value\n}, {\n  \"name\": \"filePath\",\n  \"symbols\": [\"filePath\", {\n    \"literal\": \"/\"\n  }, \"fileName\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"filePath\",\n  \"symbols\": [\"fileName\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"fileName\",\n  \"symbols\": [\"fileName\", {\n    \"literal\": \".\"\n  }, \"fileWord\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"fileName\",\n  \"symbols\": [\"fileWord\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"fileWord\",\n  \"symbols\": [\"fileWord\", \"fileChar\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"fileWord\",\n  \"symbols\": [\"fileChar\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"fileChar\",\n  \"symbols\": [/[^ ^\\/^.]/],\n  \"postprocess\": ([tok]) => tok.value\n}, {\n  \"name\": \"password\",\n  \"symbols\": [\"urlSafePlusEncoded\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"email\",\n  \"symbols\": [\"subdomain\", {\n    \"literal\": \"@\"\n  }, \"domain\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"uriDomainComponent\",\n  \"symbols\": [\"uriDomainComponent\", \"uriPortComponent\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"uriDomainComponent\",\n  \"symbols\": [\"domain\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"uriDomainComponent\",\n  \"symbols\": [{\n    \"literal\": \"[\"\n  }, \"ipv6\", {\n    \"literal\": \"]\"\n  }],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"uriDomainComponent\",\n  \"symbols\": [\"ipv4\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"ipv6$macrocall$2\",\n  \"symbols\": [\"ipv6Group\"]\n}, {\n  \"name\": \"ipv6$macrocall$1\",\n  \"symbols\": [\"ipv6$macrocall$2\", \"ipv6$macrocall$2\", \"ipv6$macrocall$2\", \"ipv6$macrocall$2\", \"ipv6$macrocall$2\", \"ipv6$macrocall$2\", \"ipv6$macrocall$2\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"ipv6\",\n  \"symbols\": [\"ipv6$macrocall$1\", \"ipv6Number\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"ipv6$macrocall$4\",\n  \"symbols\": [\"ipv6Group\"]\n}, {\n  \"name\": \"ipv6$macrocall$3\",\n  \"symbols\": [\"ipv6$macrocall$4\", \"ipv6$macrocall$4\", \"ipv6$macrocall$4\", \"ipv6$macrocall$4\", \"ipv6$macrocall$4\", \"ipv6$macrocall$4\", \"ipv6$macrocall$4\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"ipv6$macrocall$3\",\n  \"symbols\": [\"ipv6$macrocall$4\", \"ipv6$macrocall$4\", \"ipv6$macrocall$4\", \"ipv6$macrocall$4\", \"ipv6$macrocall$4\", \"ipv6$macrocall$4\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"ipv6$macrocall$3\",\n  \"symbols\": [\"ipv6$macrocall$4\", \"ipv6$macrocall$4\", \"ipv6$macrocall$4\", \"ipv6$macrocall$4\", \"ipv6$macrocall$4\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"ipv6$macrocall$3\",\n  \"symbols\": [\"ipv6$macrocall$4\", \"ipv6$macrocall$4\", \"ipv6$macrocall$4\", \"ipv6$macrocall$4\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"ipv6$macrocall$3\",\n  \"symbols\": [\"ipv6$macrocall$4\", \"ipv6$macrocall$4\", \"ipv6$macrocall$4\", \"ipv6$macrocall$4\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"ipv6$macrocall$3\",\n  \"symbols\": [\"ipv6$macrocall$4\", \"ipv6$macrocall$4\", \"ipv6$macrocall$4\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"ipv6$macrocall$3\",\n  \"symbols\": [\"ipv6$macrocall$4\", \"ipv6$macrocall$4\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"ipv6$macrocall$3\",\n  \"symbols\": [\"ipv6$macrocall$4\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"ipv6\",\n  \"symbols\": [\"ipv6$macrocall$3\", {\n    \"literal\": \":\"\n  }, \"ipv6Number\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"ipv6Group\",\n  \"symbols\": [\"ipv6Number\", {\n    \"literal\": \":\"\n  }],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"ipv6Number$macrocall$2\",\n  \"symbols\": [\"hexDigit\"]\n}, {\n  \"name\": \"ipv6Number$macrocall$1\",\n  \"symbols\": [\"ipv6Number$macrocall$2\", \"ipv6Number$macrocall$2\", \"ipv6Number$macrocall$2\", \"ipv6Number$macrocall$2\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"ipv6Number$macrocall$1\",\n  \"symbols\": [\"ipv6Number$macrocall$2\", \"ipv6Number$macrocall$2\", \"ipv6Number$macrocall$2\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"ipv6Number$macrocall$1\",\n  \"symbols\": [\"ipv6Number$macrocall$2\", \"ipv6Number$macrocall$2\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"ipv6Number$macrocall$1\",\n  \"symbols\": [\"ipv6Number$macrocall$2\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"ipv6Number\",\n  \"symbols\": [\"ipv6Number$macrocall$1\"]\n}, {\n  \"name\": \"ipv4\",\n  \"symbols\": [\"ipv4Group\", {\n    \"literal\": \".\"\n  }, \"ipv4Group\", {\n    \"literal\": \".\"\n  }, \"ipv4Group\", {\n    \"literal\": \".\"\n  }, \"ipv4Group\"]\n}, {\n  \"name\": \"ipv4Group\",\n  \"symbols\": [\"d2\", \"d5\", \"d0_5\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"ipv4Group\",\n  \"symbols\": [\"d2\", \"d0_4\", \"d0_9\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"ipv4Group\",\n  \"symbols\": [\"d1\", \"d0_9\", \"d0_9\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"ipv4Group\",\n  \"symbols\": [\"d0_9\", \"d0_9\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"ipv4Group\",\n  \"symbols\": [\"d0_9\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"d1\",\n  \"symbols\": [{\n    \"literal\": \"1\"\n  }],\n  \"postprocess\": ([tok]) => tok\n}, {\n  \"name\": \"d2\",\n  \"symbols\": [{\n    \"literal\": \"2\"\n  }],\n  \"postprocess\": ([tok]) => tok\n}, {\n  \"name\": \"d5\",\n  \"symbols\": [{\n    \"literal\": \"5\"\n  }],\n  \"postprocess\": ([tok]) => tok\n}, {\n  \"name\": \"d0_4\",\n  \"symbols\": [/[0-4]/],\n  \"postprocess\": ([tok]) => tok\n}, {\n  \"name\": \"d0_5\",\n  \"symbols\": [/[0-5]/],\n  \"postprocess\": ([tok]) => tok\n}, {\n  \"name\": \"d0_9\",\n  \"symbols\": [/[0-9]/],\n  \"postprocess\": ([tok]) => tok\n}, {\n  \"name\": \"domain\",\n  \"symbols\": [\"subdomain\", {\n    \"literal\": \".\"\n  }, \"domainComponent\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"uriPortComponent\",\n  \"symbols\": [{\n    \"literal\": \":\"\n  }, \"number\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"subdomain\",\n  \"symbols\": [\"domainComponent\", {\n    \"literal\": \".\"\n  }, \"subdomain\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"subdomain\",\n  \"symbols\": [\"domainComponent\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"uriQuery\",\n  \"symbols\": [{\n    \"literal\": \"?\"\n  }, \"queryList\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"queryList\",\n  \"symbols\": [\"queryList\", {\n    \"literal\": \"&\"\n  }, \"queryFragment\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"queryList\",\n  \"symbols\": [\"queryFragment\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"queryFragment\",\n  \"symbols\": [\"queryFragment\", {\n    \"literal\": \"=\"\n  }, \"urlSafePlusEncoded\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"queryFragment\",\n  \"symbols\": [\"urlSafePlusEncoded\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"uriFragment\",\n  \"symbols\": [{\n    \"literal\": \"#\"\n  }, \"queryList\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"domainComponent$ebnf$1\",\n  \"symbols\": []\n}, {\n  \"name\": \"domainComponent$ebnf$1\",\n  \"symbols\": [\"domainComponent$ebnf$1\", /[a-zA-Z0-9\\-]/],\n  \"postprocess\": d => d[0].concat([d[1]])\n}, {\n  \"name\": \"domainComponent\",\n  \"symbols\": [/[a-zA-Z]/, \"domainComponent$ebnf$1\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"optionalTail\"]\n}, {\n  \"name\": \"urlSafePlusEncoded\",\n  \"symbols\": [\"urlSafePlusEncoded\", \"urlSafePlusEncodedChars\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"urlSafePlusEncoded\",\n  \"symbols\": [\"urlSafePlusEncodedChars\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"urlSafePlusEncodedChars\",\n  \"symbols\": [{\n    \"literal\": \"%\"\n  }, \"hexDigit\", \"hexDigit\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"urlSafePlusEncodedChars\",\n  \"symbols\": [{\n    \"literal\": \"&\"\n  }, {\n    \"literal\": \"a\"\n  }, {\n    \"literal\": \"m\"\n  }, {\n    \"literal\": \"p\"\n  }, {\n    \"literal\": \";\"\n  }],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"urlSafePlusEncodedChars\",\n  \"symbols\": [\"urlSafeChar\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"nestedScope\",\n  \"symbols\": [\"pushScope\", \"scope\", \"popScope\"],\n  \"postprocess\": ([push, scope]) => scope\n}, {\n  \"name\": \"pushScope$subexpression$1\",\n  \"symbols\": [\"inlineComment\"]\n}, {\n  \"name\": \"pushScope$subexpression$1\",\n  \"symbols\": [\"eol\"]\n}, {\n  \"name\": \"pushScope\",\n  \"symbols\": [\"pushScope$subexpression$1\", \"indent\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"popScope\",\n  \"symbols\": [\"dedent\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"endLine\",\n  \"symbols\": [\"inlineComment\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"endLine\",\n  \"symbols\": [\"eol\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"inlineComment\",\n  \"symbols\": [\"space\", \"comment\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"comment$ebnf$1\",\n  \"symbols\": [\"_escapedString\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"comment$ebnf$1\",\n  \"symbols\": [],\n  \"postprocess\": () => null\n}, {\n  \"name\": \"comment\",\n  \"symbols\": [{\n    \"literal\": \"#\"\n  }, \"comment$ebnf$1\", eol],\n  \"postprocess\": ([operator, comment]) => comment\n}, {\n  \"name\": \"number\",\n  \"symbols\": [\"_number\"],\n  \"postprocess\": ([n]) => parseFloat(n)\n}, {\n  \"name\": \"_number\",\n  \"symbols\": [\"_float\", {\n    \"literal\": \"e\"\n  }, \"digit\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"_number\",\n  \"symbols\": [\"_float\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"_float\",\n  \"symbols\": [\"digit\", {\n    \"literal\": \".\"\n  }, \"digit\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"_float\",\n  \"symbols\": [\"digit\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"digit\",\n  \"symbols\": [\"digit\", /[0-9]/],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"concat\"]\n}, {\n  \"name\": \"digit\",\n  \"symbols\": [/[0-9]/],\n  \"postprocess\": ([tok]) => tok\n}, {\n  \"name\": \"literal\",\n  \"symbols\": [\"string\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"literal\",\n  \"symbols\": [\"singleWord\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"literal\",\n  \"symbols\": [\"uri\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"literal\",\n  \"symbols\": [\"number\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"singleWord$ebnf$1\",\n  \"symbols\": []\n}, {\n  \"name\": \"singleWord$ebnf$1\",\n  \"symbols\": [\"singleWord$ebnf$1\", /[a-zA-Z0-9$_]/],\n  \"postprocess\": d => d[0].concat([d[1]])\n}, {\n  \"name\": \"singleWord\",\n  \"symbols\": [/[a-zA-Z$_]/, \"singleWord$ebnf$1\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"optionalTail\"]\n}, {\n  \"name\": \"word\",\n  \"symbols\": [\"word\", \"wordSafeChar\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"concat\"]\n}, {\n  \"name\": \"word\",\n  \"symbols\": [\"wordStartChar\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"wordSafeChar\",\n  \"symbols\": [\"wordStartChar\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"wordSafeChar\",\n  \"symbols\": [/[0-9]/],\n  \"postprocess\": ([tok]) => tok.value\n}, {\n  \"name\": \"wordStartChar\",\n  \"symbols\": [/[a-zA-Z$_]/],\n  \"postprocess\": ([tok]) => tok.value\n}, {\n  \"name\": \"string\",\n  \"symbols\": [{\n    \"literal\": \"`\"\n  }, \"_escapedString\", {\n    \"literal\": \"`\"\n  }],\n  \"postprocess\": function (d) {\n    return d[1];\n  }\n}, {\n  \"name\": \"_string\",\n  \"symbols\": [],\n  \"postprocess\": function () {\n    return \"\";\n  }\n}, {\n  \"name\": \"_string\",\n  \"symbols\": [\"_string\", \"_stringchar\"],\n  \"postprocess\": ([lhs, rhs]) => lhs + rhs\n}, {\n  \"name\": \"_stringchar\",\n  \"symbols\": [/[^\\\\\"]/],\n  \"postprocess\": id\n}, {\n  \"name\": \"_stringchar\",\n  \"symbols\": [{\n    \"literal\": \"\\\\\"\n  }, /[^]/],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"concat\"]\n}, {\n  \"name\": \"hexDigit\",\n  \"symbols\": [/[0-9a-fA-F]/],\n  \"postprocess\": id\n}, {\n  \"name\": \"urlSafe\",\n  \"symbols\": [\"urlSafe\", \"urlSafeChar\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"concat\"]\n}, {\n  \"name\": \"urlSafe\",\n  \"symbols\": [\"urlSafeChar\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"urlSafeChar\",\n  \"symbols\": [/[a-zA-Z0-9\\-]/],\n  \"postprocess\": ([tok]) => tok.value\n}, {\n  \"name\": \"_escapedString\",\n  \"symbols\": [\"_escapedString\", \"escapedChar\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"concat\"]\n}, {\n  \"name\": \"_escapedString\",\n  \"symbols\": [\"escapedChar\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"escapedChar\",\n  \"symbols\": [space],\n  \"postprocess\": ([tok]) => tok.value\n}, {\n  \"name\": \"escapedChar\",\n  \"symbols\": [any],\n  \"postprocess\": ([tok]) => tok.value\n}, {\n  \"name\": \"sof\",\n  \"symbols\": [sof],\n  \"postprocess\": ([tok]) => tok.value\n}, {\n  \"name\": \"eof\",\n  \"symbols\": [eof],\n  \"postprocess\": ([tok]) => tok.value\n}, {\n  \"name\": \"sol\",\n  \"symbols\": [sol],\n  \"postprocess\": ([tok]) => tok\n}, {\n  \"name\": \"eol\",\n  \"symbols\": [\"_\", eol],\n  \"postprocess\": ([ws, tok]) => tok\n}, {\n  \"name\": \"indent\",\n  \"symbols\": [indent],\n  \"postprocess\": ([tok]) => tok\n}, {\n  \"name\": \"dedent\",\n  \"symbols\": [dedent],\n  \"postprocess\": ([tok]) => tok\n}, {\n  \"name\": \"space\",\n  \"symbols\": [space],\n  \"postprocess\": ([tok]) => tok.value\n}, {\n  \"name\": \"_\",\n  \"symbols\": [\"_\", \"space\"],\n  \"postprocess\": ([e]) => {\n    return e ? e + ' ' : '';\n  }\n}, {\n  \"name\": \"_\",\n  \"symbols\": [],\n  \"postprocess\": () => ''\n}, {\n  \"name\": \"start\",\n  \"symbols\": [\"sof\", \"rootScope\", \"eof\"],\n  \"postprocess\": ([sof, scope]) => scope\n}, {\n  \"name\": \"rootScope\",\n  \"symbols\": [\"map\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"rootScope$subexpression$1\",\n  \"symbols\": [\"sol\", \"eol\", {\n    \"literal\": \"string\"\n  }]\n}, {\n  \"name\": \"rootScope$subexpression$2\",\n  \"symbols\": [{\n    \"literal\": \"/string\"\n  }]\n}, {\n  \"name\": \"rootScope\",\n  \"symbols\": [\"rootScope$subexpression$1\", \"multilineString\", \"rootScope$subexpression$2\"],\n  \"postprocess\": ([sol, scope]) => scope\n}, {\n  \"name\": \"scope\",\n  \"symbols\": [\"map\"],\n  \"postprocess\": ([layer]) => layer.data\n}, {\n  \"name\": \"map\",\n  \"symbols\": [\"map\", \"mapPairConstructor\"],\n  \"postprocess\": ([_layer, nextMatch]) => {\n    const layer = {\n      data: new Map(_layer.data),\n      context: {}\n    };\n\n    if (nextMatch && nextMatch[0] !== undefined) {\n      Object(_post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"addPairToMap\"])(nextMatch, layer.data);\n    }\n\n    return layer;\n  }\n}, {\n  \"name\": \"map\",\n  \"symbols\": [\"map\", \"mapList\"],\n  \"postprocess\": ([_layer, list]) => {\n    const layer = {\n      data: new Map(_layer.data),\n      context: {}\n    };\n\n    if (list && list.length) {\n      for (let i = 0; i < list.length; i++) {\n        Object(_post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"addPairToMap\"])([i, list[i]], layer.data);\n      }\n    }\n\n    return layer;\n  }\n}, {\n  \"name\": \"map\",\n  \"symbols\": [\"mapPairConstructor\"],\n  \"postprocess\": ([initialMatch]) => {\n    const layer = {\n      data: new Map(),\n      context: {}\n    };\n\n    if (initialMatch && initialMatch[0] !== undefined) {\n      Object(_post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"addPairToMap\"])(initialMatch, layer.data);\n    }\n\n    return layer;\n  }\n}, {\n  \"name\": \"map\",\n  \"symbols\": [\"mapList\"],\n  \"postprocess\": ([list]) => {\n    const layer = {\n      data: new Map(),\n      context: {}\n    };\n\n    if (list && list.length) {\n      for (let i = 0; i < list.length; i++) {\n        Object(_post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"addPairToMap\"])([i, list[i]], layer.data);\n      }\n    }\n\n    return layer;\n  }\n}, {\n  \"name\": \"mapList$subexpression$1\",\n  \"symbols\": [\"sol\", {\n    \"literal\": \"-<\"\n  }, \"endLine\"]\n}, {\n  \"name\": \"mapList\",\n  \"symbols\": [\"mapList$subexpression$1\", \"list\", {\n    \"literal\": \"/-<\"\n  }],\n  \"postprocess\": ([prefix, list]) => list\n}, {\n  \"name\": \"mapPairConstructor$subexpression$1$subexpression$1\",\n  \"symbols\": [\"space\", \"constraintMap\"]\n}, {\n  \"name\": \"mapPairConstructor$subexpression$1\",\n  \"symbols\": [\"mapPairConstructor$subexpression$1$subexpression$1\"]\n}, {\n  \"name\": \"mapPairConstructor$subexpression$1\",\n  \"symbols\": [\"space\"]\n}, {\n  \"name\": \"mapPairConstructor$subexpression$2\",\n  \"symbols\": [{\n    \"literal\": \"-<\"\n  }, \"pushScope\"]\n}, {\n  \"name\": \"mapPairConstructor\",\n  \"symbols\": [\"key\", \"mapPairConstructor$subexpression$1\", \"mapPairConstructor$subexpression$2\", \"list\", {\n    \"literal\": \"/-<\"\n  }, \"popScope\"],\n  \"postprocess\": ([key, context, mode, scope]) => {\n    if (context) {\n      return [key, scope, {\n        multiLineString: true,\n        ...context[1]\n      }];\n    } else {\n      return [key, scope, {\n        multiLineString: true\n      }];\n    }\n  }\n}, {\n  \"name\": \"mapPairConstructor$subexpression$3$subexpression$1\",\n  \"symbols\": [\"space\", \"constraintMap\"]\n}, {\n  \"name\": \"mapPairConstructor$subexpression$3\",\n  \"symbols\": [\"mapPairConstructor$subexpression$3$subexpression$1\"]\n}, {\n  \"name\": \"mapPairConstructor$subexpression$3\",\n  \"symbols\": [\"space\"]\n}, {\n  \"name\": \"mapPairConstructor$subexpression$4\",\n  \"symbols\": [\"eol\", {\n    \"literal\": \"text\"\n  }, \"indent\"]\n}, {\n  \"name\": \"mapPairConstructor\",\n  \"symbols\": [\"key\", \"mapPairConstructor$subexpression$3\", \"mapPairConstructor$subexpression$4\", \"multilineString\", \"popScope\", {\n    \"literal\": \"/text\"\n  }],\n  \"postprocess\": ([key, context, mode, scope]) => {\n    if (context) {\n      return [key, scope, {\n        multiLineString: true,\n        ...context[1]\n      }];\n    } else {\n      return [key, scope, {\n        multiLineString: true\n      }];\n    }\n  }\n}, {\n  \"name\": \"mapPairConstructor\",\n  \"symbols\": [\"key\", \"pushTypedScope\", \"scope\", \"popScope\"],\n  \"postprocess\": ([key, context, scope]) => {\n    return [key, scope];\n  }\n}, {\n  \"name\": \"mapPairConstructor$subexpression$5$subexpression$1\",\n  \"symbols\": [\"space\", \"constraintMap\"]\n}, {\n  \"name\": \"mapPairConstructor$subexpression$5\",\n  \"symbols\": [\"mapPairConstructor$subexpression$5$subexpression$1\"]\n}, {\n  \"name\": \"mapPairConstructor$subexpression$5\",\n  \"symbols\": [\"space\"]\n}, {\n  \"name\": \"mapPairConstructor\",\n  \"symbols\": [\"key\", \"mapPairConstructor$subexpression$5\", {\n    \"literal\": \"{\"\n  }, \"scope\", {\n    \"literal\": \"}\"\n  }, \"endLine\"],\n  \"postprocess\": ([key, context, bracket, scope]) => {\n    return [key, scope];\n  }\n}, {\n  \"name\": \"mapPairConstructor$subexpression$6$subexpression$1\",\n  \"symbols\": [\"space\", \"constraintMap\"]\n}, {\n  \"name\": \"mapPairConstructor$subexpression$6\",\n  \"symbols\": [\"mapPairConstructor$subexpression$6$subexpression$1\"]\n}, {\n  \"name\": \"mapPairConstructor$subexpression$6\",\n  \"symbols\": [\"space\"]\n}, {\n  \"name\": \"mapPairConstructor\",\n  \"symbols\": [\"key\", \"mapPairConstructor$subexpression$6\", \"statement\", \"mapTerminator\"],\n  \"postprocess\": ([key, context, statement]) => {\n    console.log('pair', [key, statement]);\n    return [key, statement];\n  }\n}, {\n  \"name\": \"mapPairConstructor$subexpression$7\",\n  \"symbols\": [\"sol\"]\n}, {\n  \"name\": \"mapPairConstructor$subexpression$7\",\n  \"symbols\": [\"space\"]\n}, {\n  \"name\": \"mapPairConstructor$ebnf$1$subexpression$1\",\n  \"symbols\": [\"constraintMap\"]\n}, {\n  \"name\": \"mapPairConstructor$ebnf$1\",\n  \"symbols\": [\"mapPairConstructor$ebnf$1$subexpression$1\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"mapPairConstructor$ebnf$1\",\n  \"symbols\": [],\n  \"postprocess\": () => null\n}, {\n  \"name\": \"mapPairConstructor\",\n  \"symbols\": [\"mapPairConstructor$subexpression$7\", \"mapPairConstructor$ebnf$1\", \"statement\", \"mapTerminator\"],\n  \"postprocess\": ([prefix, constraintMap, statement]) => {\n    return [statement, true];\n  }\n}, {\n  \"name\": \"mapPairConstructor\",\n  \"symbols\": [\"sol\", \"eol\"],\n  \"postprocess\": () => null\n}, {\n  \"name\": \"mapPairConstructor\",\n  \"symbols\": [\"sol\", \"comment\"],\n  \"postprocess\": () => null\n}, {\n  \"name\": \"mapPairConstructor\",\n  \"symbols\": [\"literal\", \"pushScope\", \"scope\"],\n  \"postprocess\": _post_errors__WEBPACK_IMPORTED_MODULE_1__[\"expectedScopeOperator\"]\n}, {\n  \"name\": \"mapTerminator$subexpression$1\",\n  \"symbols\": [{\n    \"literal\": \" \"\n  }]\n}, {\n  \"name\": \"mapTerminator$subexpression$1\",\n  \"symbols\": [{\n    \"literal\": \",\"\n  }]\n}, {\n  \"name\": \"mapTerminator$subexpression$1\",\n  \"symbols\": [\"endLine\"]\n}, {\n  \"name\": \"mapTerminator\",\n  \"symbols\": [\"mapTerminator$subexpression$1\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"listTerminator$subexpression$1\",\n  \"symbols\": [{\n    \"literal\": \",\"\n  }]\n}, {\n  \"name\": \"listTerminator$subexpression$1\",\n  \"symbols\": [\"endLine\"]\n}, {\n  \"name\": \"listTerminator\",\n  \"symbols\": [\"listTerminator$subexpression$1\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"list\",\n  \"symbols\": [\"list\", \"listConstructor\"],\n  \"postprocess\": ([array, item]) => {\n    if (item) {\n      return [...array, item];\n    }\n\n    return array;\n  }\n}, {\n  \"name\": \"list\",\n  \"symbols\": [\"listConstructor\"],\n  \"postprocess\": ([item]) => {\n    return [item];\n  }\n}, {\n  \"name\": \"listConstructor\",\n  \"symbols\": [\"key\", \"pushTypedScope\", \"scope\", \"popScope\"],\n  \"postprocess\": ([key, context, scope]) => {\n    return scope;\n  }\n}, {\n  \"name\": \"listConstructor$subexpression$1$subexpression$1\",\n  \"symbols\": [\"space\", \"constraintMap\"]\n}, {\n  \"name\": \"listConstructor$subexpression$1\",\n  \"symbols\": [\"listConstructor$subexpression$1$subexpression$1\"]\n}, {\n  \"name\": \"listConstructor$subexpression$1\",\n  \"symbols\": [\"space\"]\n}, {\n  \"name\": \"listConstructor\",\n  \"symbols\": [\"key\", \"listConstructor$subexpression$1\", {\n    \"literal\": \"{\"\n  }, \"scope\", {\n    \"literal\": \"}\"\n  }, \"endLine\"],\n  \"postprocess\": ([key, context, bracket, scope]) => {\n    return scope;\n  }\n}, {\n  \"name\": \"listConstructor$subexpression$2$subexpression$1\",\n  \"symbols\": [\"space\", \"constraintMap\"]\n}, {\n  \"name\": \"listConstructor$subexpression$2\",\n  \"symbols\": [\"listConstructor$subexpression$2$subexpression$1\"]\n}, {\n  \"name\": \"listConstructor$subexpression$2\",\n  \"symbols\": [\"space\"]\n}, {\n  \"name\": \"listConstructor\",\n  \"symbols\": [\"key\", \"listConstructor$subexpression$2\", \"statement\", \"listTerminator\"],\n  \"postprocess\": ([key, context, statement]) => {\n    return statement;\n  }\n}, {\n  \"name\": \"listConstructor$subexpression$3\",\n  \"symbols\": [\"sol\"]\n}, {\n  \"name\": \"listConstructor$subexpression$3\",\n  \"symbols\": [\"space\"]\n}, {\n  \"name\": \"listConstructor$ebnf$1$subexpression$1\",\n  \"symbols\": [\"constraintMap\"]\n}, {\n  \"name\": \"listConstructor$ebnf$1\",\n  \"symbols\": [\"listConstructor$ebnf$1$subexpression$1\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"listConstructor$ebnf$1\",\n  \"symbols\": [],\n  \"postprocess\": () => null\n}, {\n  \"name\": \"listConstructor\",\n  \"symbols\": [\"listConstructor$subexpression$3\", \"listConstructor$ebnf$1\", \"statement\", \"listTerminator\"],\n  \"postprocess\": ([prefix, constraintMap, statement]) => {\n    return statement;\n  }\n}, {\n  \"name\": \"listConstructor\",\n  \"symbols\": [\"sol\", \"eol\"],\n  \"postprocess\": () => null\n}, {\n  \"name\": \"listConstructor\",\n  \"symbols\": [\"sol\", \"comment\"],\n  \"postprocess\": () => null\n}, {\n  \"name\": \"multilineString$ebnf$1\",\n  \"symbols\": []\n}, {\n  \"name\": \"multilineString$ebnf$1\",\n  \"symbols\": [\"multilineString$ebnf$1\", \"stringLine\"],\n  \"postprocess\": d => d[0].concat([d[1]])\n}, {\n  \"name\": \"multilineString\",\n  \"symbols\": [\"stringLine\", \"multilineString$ebnf$1\"],\n  \"postprocess\": ([head, tail]) => {\n    const [startIndent, mls] = head;\n\n    if (tail.length) {\n      const res = tail.map(([indent, line]) => {\n        let margin = '';\n\n        if (indent > startIndent) {\n          for (let i = 0; i < indent - startIndent; i++) {\n            margin = margin + ' ';\n          }\n        }\n\n        if (line) {\n          return margin + line;\n        }\n\n        return margin;\n      });\n      return [mls, ...res].join('\\n');\n    }\n\n    return mls;\n  }\n}, {\n  \"name\": \"stringLine\",\n  \"symbols\": [\"indent\", \"multilineString\", \"dedent\"],\n  \"postprocess\": ([indent, mls]) => {\n    return [indent.indent, mls];\n  }\n}, {\n  \"name\": \"stringLine$ebnf$1\",\n  \"symbols\": [\"_escapedString\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"stringLine$ebnf$1\",\n  \"symbols\": [],\n  \"postprocess\": () => null\n}, {\n  \"name\": \"stringLine\",\n  \"symbols\": [\"sol\", \"stringLine$ebnf$1\", \"eol\"],\n  \"postprocess\": ([sol, string]) => {\n    return [sol.indent, string];\n  }\n}, {\n  \"name\": \"pushTypedScope\",\n  \"symbols\": [\"space\", \"constraintMap\", \"indent\"],\n  \"postprocess\": ([space, constraintMap]) => constraintMap\n}, {\n  \"name\": \"pushTypedScope\",\n  \"symbols\": [\"pushScope\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"constraintMap\",\n  \"symbols\": [\"constraintMap\", \"constraint\"],\n  \"postprocess\": ([map, nextMatch]) => {\n    if (nextMatch) {\n      Object(_post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"addPairToMap\"])(nextMatch, map);\n    }\n\n    return map;\n  }\n}, {\n  \"name\": \"constraintMap\",\n  \"symbols\": [\"constraint\"],\n  \"postprocess\": ([initialMatch]) => {\n    const map = new Map();\n\n    if (initialMatch) {\n      Object(_post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"addPairToMap\"])(initialMatch, map);\n    }\n\n    return map;\n  }\n}, {\n  \"name\": \"constraint$subexpression$1\",\n  \"symbols\": [\"space\"]\n}, {\n  \"name\": \"constraint$subexpression$1\",\n  \"symbols\": [\"endLine\"]\n}, {\n  \"name\": \"constraint\",\n  \"symbols\": [{\n    \"literal\": \"@\"\n  }, {\n    \"literal\": \"{\"\n  }, \"nestedScope\", \"sol\", {\n    \"literal\": \"}\"\n  }, \"constraint$subexpression$1\"],\n  \"postprocess\": ([directive, bracket, scope]) => scope\n}, {\n  \"name\": \"constraint$subexpression$2\",\n  \"symbols\": [\"space\"]\n}, {\n  \"name\": \"constraint$subexpression$2\",\n  \"symbols\": [\"endLine\"]\n}, {\n  \"name\": \"constraint\",\n  \"symbols\": [{\n    \"literal\": \"@\"\n  }, \"literal\", {\n    \"literal\": \"{\"\n  }, \"scope\", {\n    \"literal\": \"}\"\n  }, \"constraint$subexpression$2\"],\n  \"postprocess\": ([directive, literal, bracket, scope]) => [literal, scope]\n}, {\n  \"name\": \"constraint$subexpression$3\",\n  \"symbols\": [\"space\"]\n}, {\n  \"name\": \"constraint$subexpression$3\",\n  \"symbols\": [\"endLine\"]\n}, {\n  \"name\": \"constraint\",\n  \"symbols\": [{\n    \"literal\": \"@\"\n  }, \"literal\", \"constraint$subexpression$3\"],\n  \"postprocess\": ([directive, property]) => {\n    return [property, true];\n  }\n}, {\n  \"name\": \"key$subexpression$1\",\n  \"symbols\": [\"sol\"]\n}, {\n  \"name\": \"key$subexpression$1\",\n  \"symbols\": [\"space\"]\n}, {\n  \"name\": \"key\",\n  \"symbols\": [\"key$subexpression$1\", \"keyExpression\", {\n    \"literal\": \":\"\n  }],\n  \"postprocess\": ([pre, key]) => key\n}, {\n  \"name\": \"keyExpression$subexpression$1\",\n  \"symbols\": [{\n    \"literal\": \"=\"\n  }]\n}, {\n  \"name\": \"keyExpression$subexpression$1\",\n  \"symbols\": [{\n    \"literal\": \"+\"\n  }]\n}, {\n  \"name\": \"keyExpression$subexpression$1\",\n  \"symbols\": [{\n    \"literal\": \"|\"\n  }]\n}, {\n  \"name\": \"keyExpression$subexpression$1\",\n  \"symbols\": [{\n    \"literal\": \"&\"\n  }]\n}, {\n  \"name\": \"keyExpression$subexpression$1\",\n  \"symbols\": [{\n    \"literal\": \"^\"\n  }]\n}, {\n  \"name\": \"keyExpression$subexpression$1\",\n  \"symbols\": [{\n    \"literal\": \"-\"\n  }]\n}, {\n  \"name\": \"keyExpression\",\n  \"symbols\": [\"keyExpression$subexpression$1\", \"space\", \"statement\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"keyExpression\",\n  \"symbols\": [\"concat\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"statement\",\n  \"symbols\": [\"concat\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"concat\",\n  \"symbols\": [\"concat\", \"space\", \"boolean\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"concat\",\n  \"symbols\": [\"boolean\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"boolean$subexpression$1\",\n  \"symbols\": [{\n    \"literal\": \"n\"\n  }]\n}, {\n  \"name\": \"boolean$subexpression$1\",\n  \"symbols\": [{\n    \"literal\": \"|\"\n  }]\n}, {\n  \"name\": \"boolean\",\n  \"symbols\": [\"boolean\", \"space\", \"boolean$subexpression$1\", \"space\", \"add\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"boolean\",\n  \"symbols\": [\"add\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"add$subexpression$1\",\n  \"symbols\": [{\n    \"literal\": \"+\"\n  }]\n}, {\n  \"name\": \"add$subexpression$1\",\n  \"symbols\": [{\n    \"literal\": \"-\"\n  }]\n}, {\n  \"name\": \"add\",\n  \"symbols\": [\"add\", \"space\", \"add$subexpression$1\", \"space\", \"multiply\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"add\",\n  \"symbols\": [\"multiply\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"multiply$subexpression$1\",\n  \"symbols\": [{\n    \"literal\": \"*\"\n  }]\n}, {\n  \"name\": \"multiply$subexpression$1\",\n  \"symbols\": [{\n    \"literal\": \"/\"\n  }]\n}, {\n  \"name\": \"multiply\",\n  \"symbols\": [\"multiply\", \"space\", \"multiply$subexpression$1\", \"space\", \"unaryPrefix\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"multiply\",\n  \"symbols\": [\"unaryPrefix\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"unaryPrefix\",\n  \"symbols\": [{\n    \"literal\": \"+\"\n  }, \"group\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"unaryPrefix\",\n  \"symbols\": [{\n    \"literal\": \"-\"\n  }, \"group\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"unaryPrefix\",\n  \"symbols\": [{\n    \"literal\": \"!\"\n  }, \"group\"],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"unaryPrefix\",\n  \"symbols\": [\"group\"],\n  \"postprocess\": id\n}, {\n  \"name\": \"group\",\n  \"symbols\": [{\n    \"literal\": \"(\"\n  }, \"concat\", {\n    \"literal\": \")\"\n  }],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"group\",\n  \"symbols\": [{\n    \"literal\": \"$\"\n  }, {\n    \"literal\": \"{\"\n  }, \"concat\", {\n    \"literal\": \"}\"\n  }],\n  \"postprocess\": _post_reducers__WEBPACK_IMPORTED_MODULE_2__[\"reduce\"]\n}, {\n  \"name\": \"group\",\n  \"symbols\": [\"literal\"],\n  \"postprocess\": id\n}];\nvar ParserStart = \"start\";\n\n//# sourceURL=webpack:///./src/nearley/index.ts?");

/***/ }),

/***/ "./src/nearley/lexer.ts":
/*!******************************!*\
  !*** ./src/nearley/lexer.ts ***!
  \******************************/
/*! exports provided: lexer */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"lexer\", function() { return lexer; });\nconst moo = __webpack_require__(/*! moo */ \"../../node_modules/moo/moo.js\");\n\nconst makeToken = (type, text, sourceMap, indent) => ({ ...sourceMap,\n  type,\n  text,\n  value: text,\n  indent,\n  toString: () => text\n});\n\nconst makeSol = (sourceMap, indent) => {\n  const t = makeToken('sol', '\\n', sourceMap, indent); //console.log(t);\n\n  return t;\n};\n\nconst makeEol = (sourceMap, indent) => makeToken('eol', '\\n', sourceMap, indent);\n\nconst makeIndent = (sourceMap, indent) => makeToken('indent', 'indent', sourceMap, indent);\n\nconst makeDedent = (sourceMap, indent) => makeToken('dedent', 'dedent', sourceMap, indent);\n\nconst makeSof = () => makeToken('sof', 'sof');\n\nconst makeEof = () => makeToken('eof', 'eof');\n\nconst doDedent = (ruleMap, indent, nextIndent, sourceMap) => {\n  const tokens = [makeEol(sourceMap, indent)];\n  const ruleToken = ruleMap.get(indent);\n\n  if (ruleToken) {\n    tokens.push(makeToken('stopRule', `/${ruleToken.text}`, sourceMap, indent));\n    ruleMap.delete(indent);\n  }\n\n  tokens.push(makeDedent(sourceMap, nextIndent));\n  tokens.push(makeSol(sourceMap, nextIndent));\n  return tokens;\n};\n\nfunction* indented(lexer, source, info) {\n  let iter = peekable(lexer.reset(source, info));\n  let stack = [];\n  let ruleMap = new Map(); // absorb initial blank lines and indentation\n\n  let indent = iter.nextIndent();\n  yield makeSof();\n  yield makeSol(null, indent);\n\n  for (let tok; tok = iter.next();) {\n    const sourceMap = {\n      line: tok.line,\n      col: tok.col\n    };\n\n    if (tok.type === 'eol' || tok.type === 'startRule') {\n      const newIndent = iter.nextIndent();\n\n      if (newIndent == null) {\n        break;\n      } // eof\n      else if (newIndent === indent) {\n          if (tok.type === 'startRule') {\n            const ruleToken = makeToken('startRule', tok.text.slice(0, tok.text.indexOf('<') + 1));\n            ruleMap.set(indent, ruleToken);\n            yield ruleToken;\n          }\n\n          yield makeEol(sourceMap, indent);\n          yield makeSol(sourceMap, indent);\n        } else if (newIndent > indent) {\n          stack.push(indent);\n          indent = newIndent;\n\n          if (tok.type === 'startRule') {\n            const ruleToken = makeToken('startRule', tok.text.slice(0, tok.text.indexOf('<') + 1));\n            ruleMap.set(indent, ruleToken);\n            yield ruleToken;\n          }\n\n          yield makeEol(sourceMap, indent);\n          yield makeIndent(sourceMap, indent);\n          yield makeSol(sourceMap, indent);\n        } else if (newIndent < indent) {\n          while (newIndent < indent) {\n            const nextIndent = stack.pop();\n            const dedentTokens = doDedent(ruleMap, indent, nextIndent, sourceMap);\n\n            for (const t of dedentTokens) {\n              yield t;\n            }\n\n            indent = nextIndent;\n          }\n\n          if (newIndent !== indent) {\n            throw new Error(`inconsistent indentation ${newIndent} != ${indent}`);\n          }\n        } else {\n          yield makeEol(sourceMap, indent);\n          yield makeSol(sourceMap, indent);\n        }\n\n      indent = newIndent;\n    } else {\n      yield { ...tok,\n        indent: indent\n      };\n    }\n  } // dedent remaining blocks at eof\n\n\n  for (let i = stack.length; i--;) {\n    const nextIndent = stack.pop() || 0;\n    const dedentTokens = doDedent(ruleMap, indent, nextIndent, {\n      line: 'eof',\n      col: 'eof'\n    });\n\n    for (const t of dedentTokens) {\n      yield t;\n    }\n\n    indent = nextIndent;\n  }\n\n  yield makeEol({\n    line: -1,\n    col: -1\n  }, indent);\n  const ruleToken = ruleMap.get(0);\n\n  if (ruleToken) {\n    yield makeToken('stopRule', `/${ruleToken.text}`);\n    ruleMap.delete(0);\n  }\n\n  yield makeEof();\n}\n\nfunction peekable(lexer) {\n  let here = lexer.next();\n  return {\n    next() {\n      const old = here;\n      here = lexer.next();\n      return old;\n    },\n\n    peek() {\n      return here;\n    },\n\n    nextIndent() {\n      for (let tok; tok = this.peek();) {\n        if (tok.type === 'eol') {\n          this.next();\n        } else if (tok.type === 'space') {\n          // const indent = tok.value.length;\n          const recur = indent => {\n            this.next();\n            const next = this.peek();\n            if (!next) return indent;\n\n            if (next.type === 'eol') {\n              this.next();\n              return indent;\n            } else if (next.type === 'space') {\n              return recur(indent + 1);\n            }\n\n            return indent;\n          };\n\n          return recur(1);\n        }\n\n        return 0;\n      }\n    }\n\n  };\n}\n\nconst rules = {\n  space: /[ ]/,\n  startRule: {\n    match: /[a-zA-Z+\\-`]+<[\\n\\r]|[a-zA-Z+\\-`]+< #.*[\\n\\r]/,\n    lineBreaks: true\n  },\n  eol: {\n    match: /[\\n\\r]/,\n    lineBreaks: true\n  },\n  any: /[^\\s]/\n};\n\nconst printToken = t => {\n  switch (t.type) {\n    case \"eol\":\n      return \"}\";\n\n    case \"eol\":\n      return \"}\";\n\n    case \"space\":\n      return \" \";\n\n    case \"indent\":\n      return \"->\";\n\n    case \"dedent\":\n      return \"<-\";\n\n    case \"eof\":\n      return \"</>\";\n\n    case \"sof\":\n      return \"<>\";\n\n    case \"sol\":\n      return \"{\";\n\n    default:\n      return t.text;\n  }\n};\n\nclass StreamLexer {\n  constructor() {\n    this.lexer = void 0;\n\n    this.next = function () {\n      const tok = this.generator.next().value;\n\n      if (tok) {\n        //console.log(printToken(tok), tok);\n        return tok;\n      }\n    };\n\n    this.save = function () {};\n\n    this.getTokenTypes = function (source) {\n      const types = [];\n      const iter = indented(moo.compile(rules), source);\n      const arr = [];\n\n      for (const t of iter) {\n        if (t.type == 'any') {\n          const back = arr.length ? arr[arr.length - 1] : null;\n\n          if (back && back.type == 'any') {\n            back.value += t.value;\n            back.text += t.text;\n          } else {\n            arr.push(t);\n          }\n        } else {\n          arr.push(t);\n        }\n      }\n\n      return arr.map(t => printToken(t));\n    };\n\n    this.reset = function (source, info) {\n      // console.log('tokens', this.getTokenTypes(source))\n      this.generator = indented(this.lexer, source, info);\n    };\n\n    this.formatError = function (token) {\n      return this.lexer.formatError(token);\n    };\n\n    this.has = function (name) {\n      if (name == 'indent') return true;\n      if (name == 'dedent') return true;\n      if (name == 'sof') return true;\n      if (name == 'sol') return true;\n      if (name == 'eof') return true;\n      if (name == 'eol') return true;\n      return this.lexer.has(name);\n    };\n\n    this.lexer = moo.compile(rules);\n  }\n\n}\n\nconst lexer = new StreamLexer();\n\n//# sourceURL=webpack:///./src/nearley/lexer.ts?");

/***/ }),

/***/ "./src/nearley/post/errors.ts":
/*!************************************!*\
  !*** ./src/nearley/post/errors.ts ***!
  \************************************/
/*! exports provided: expectedListNotation, emptyScope, expectedRhs, expectedTerminator, extraSpace, genericContextError, missingComma, expectedScopeOperator, missingRhs, unknownOrEmpty */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"expectedListNotation\", function() { return expectedListNotation; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"emptyScope\", function() { return emptyScope; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"expectedRhs\", function() { return expectedRhs; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"expectedTerminator\", function() { return expectedTerminator; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"extraSpace\", function() { return extraSpace; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"genericContextError\", function() { return genericContextError; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"missingComma\", function() { return missingComma; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"expectedScopeOperator\", function() { return expectedScopeOperator; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"missingRhs\", function() { return missingRhs; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"unknownOrEmpty\", function() { return unknownOrEmpty; });\nfunction expectedListNotation() {\n  throw new Error(\"expected list notation\");\n}\nfunction emptyScope() {\n  throw new Error(\"empty scope\");\n}\nfunction expectedRhs() {\n  throw new Error(\"no value for rhs\");\n}\nfunction expectedTerminator() {\n  throw new Error(\"missing map pair terminator\");\n}\nfunction extraSpace() {\n  throw new Error(\"unused space at end of line\");\n}\nfunction genericContextError() {\n  throw new Error(\"@context error\");\n}\nfunction missingComma() {\n  throw new Error(\"missing comma\");\n}\nfunction expectedScopeOperator() {\n  throw new Error(\"nested scope without scope operator\");\n}\nfunction missingRhs() {\n  throw new Error(\"rhs of pair assignment missing\");\n}\nfunction unknownOrEmpty() {\n  throw new Error(\"unknown or empty\");\n}\n\n//# sourceURL=webpack:///./src/nearley/post/errors.ts?");

/***/ }),

/***/ "./src/nearley/post/reducers.ts":
/*!**************************************!*\
  !*** ./src/nearley/post/reducers.ts ***!
  \**************************************/
/*! exports provided: joinExpressionOperator, joinSeparatedChunks, concat, lhs, rhs, back, addPairToMap, addPairToDataAndContext, join, reduce, optionalTail, map2Object */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"joinExpressionOperator\", function() { return joinExpressionOperator; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"joinSeparatedChunks\", function() { return joinSeparatedChunks; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"concat\", function() { return concat; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"lhs\", function() { return lhs; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"rhs\", function() { return rhs; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"back\", function() { return back; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"addPairToMap\", function() { return addPairToMap; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"addPairToDataAndContext\", function() { return addPairToDataAndContext; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"join\", function() { return join; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"reduce\", function() { return reduce; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"optionalTail\", function() { return optionalTail; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"map2Object\", function() { return map2Object; });\nconst joinExpressionOperator = ([lhs, s1, op, s2, rhs]) => lhs + s1 + op + s2 + rhs;\nconst joinSeparatedChunks = ([lhs, op, rhs]) => lhs + op + rhs;\nconst concat = ([lhs, rhs]) => lhs + rhs;\nconst lhs = ([lhs, rhs]) => lhs;\nconst rhs = ([lhs, rhs]) => rhs;\nconst back = d => d[d.length - 1];\nfunction addPairToMap([key, value], map) {\n  console.log('add to layer', [key, value], map);\n\n  if (map.get(key)) {\n    throw new Error(`duplicate key ${key}`);\n  }\n\n  map.set(key, value);\n}\nfunction addPairToDataAndContext([key, data, context], [dataMap, contextMap]) {\n  addPairToMap([key, data], dataMap);\n  addPairToMap([key, context], contextMap);\n}\nfunction join(list, rhs) {\n  if (!list) return rhs;\n  if (!rhs) return list;\n\n  if (typeof list == 'string') {\n    return list + rhs;\n  }\n\n  return list + rhs;\n}\nfunction reduce(list) {\n  if (list.length == 1) {\n    return list[0];\n  }\n\n  let memo;\n\n  for (const item of list) {\n    memo = join(memo, item);\n  }\n\n  return memo;\n}\nfunction optionalTail(list) {\n  const [head, tail] = list;\n\n  if (tail && tail.length) {\n    return head.value + reduce(tail);\n  }\n\n  return head.value;\n  f;\n}\nfunction map2Object(map) {\n  const object = {};\n\n  for (const pair of map) {\n    const [key] = pair;\n    object[key] = map.get(key);\n  }\n\n  return object;\n}\n\n//# sourceURL=webpack:///./src/nearley/post/reducers.ts?");

/***/ }),

/***/ 0:
/*!*************************!*\
  !*** multi ./src/index ***!
  \*************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("module.exports = __webpack_require__(/*! /Users/leif/chroma/fund/packages/moss-lang/src/index */\"./src/index.ts\");\n\n\n//# sourceURL=webpack:///multi_./src/index?");

/***/ })

/******/ });